# -*- coding: utf-8 -*-
"""GANs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kcZ1N7TFTo6B_wLRJJEdjDcHG8_L_qvE

GANs application on MNIST data
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Load and Prepare MNIST Dataset
# MNIST: data preprocessing
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)) # Normalize to range [-1, 1]
])

# Load dataset
batch_size = 64
train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Define the Generator
# The Generator takes random noise as input and produces a 28x28 image
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 784),
            nn.Tanh() # Output in range [-1, 1]
        )

    def forward(self, z):
        return self.model(z).view(z.size(0), 1, 28, 28)

latent_dim = 100
generator = Generator(latent_dim).to("cuda" if torch.cuda.is_available() else "cpu")

# Define the Discriminator
# The Discriminator takes an image as input and outputs the probability of it being real
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(784, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid() # Output probability
        )

    def forward(self, x):
        x = x.view(x.size(0), -1) # Flatten the image
        return self.model(x)

discriminator = Discriminator().to("cuda" if torch.cuda.is_available() else "cpu")

# Define Loss Function and Optimizers
# Use Binary Cross-Entropy (BCE) loss for both models
criterion = nn.BCELoss()

lr = 0.0002
generator_optimizer = optim.Adam(generator.parameters(), lr=lr)
discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr)

device = "cuda" if torch.cuda.is_available() else "cpu"
# Training the loop
def train_gan(generator, discriminator, train_loader, epochs, latent_dim):
    for epoch in range(epochs):
        for real_images, _ in train_loader:
            batch_size = real_images.size(0)
            real_images = real_images.to(device)

            # Labels
            real_labels = torch.ones(batch_size, 1).to(device)
            fake_labels = torch.zeros(batch_size, 1).to(device)

            # Train Discriminator
            discriminator_optimizer.zero_grad()

            # Loss for real images
            real_outputs = discriminator(real_images)
            real_loss = criterion(real_outputs, real_labels)

            # Generate fake images
            noise = torch.randn(batch_size, latent_dim).to(device)
            fake_images = generator(noise)

            # Loss for fake images
            fake_outputs = discriminator(fake_images.detach())
            fake_loss = criterion(fake_outputs, fake_labels)

            # Total Discriminator loss
            d_loss = real_loss + fake_loss
            d_loss.backward()
            discriminator_optimizer.step()

            # Train Generator
            generator_optimizer.zero_grad()

            # Generate fake images and calculate loss
            fake_outputs = discriminator(fake_images)
            g_loss = criterion(fake_outputs, real_labels) # Fool the discriminator

            g_loss.backward()
            generator_optimizer.step()

        # Print losses for the current epoch
        print(f"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} G Loss: {g_loss.item():.4f}")

        # Visualize generated images
        if (epoch + 1) % 10 == 0:
            visualize_images(generator, latent_dim)

# Visualization Function
def visualize_images(generator, latent_dim, num_images=16):
    generator.eval()
    noise = torch.randn(num_images, latent_dim).to(device)
    generated_images = generator(noise).detach().cpu()

    # Plot Images
    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))
    if num_images == 1:
        axes.imshow(generated_images[0].squeeze(), cmap="gray")
        axes.axis("off")
    else:
        for i in range(num_images):
            axes[i].imshow(generated_images[i].squeeze(), cmap="gray")
            axes[i].axis("off")
    plt.show()
    generator.train()

# Run the Training
epochs = 50
train_gan(generator, discriminator, train_loader, epochs, latent_dim)

# Generate and Visualize New Images (Post-Training)
def generate_images(generator, latent_dim, num_images=16):
    generator.eval()
    noise = torch.randn(num_images, latent_dim).to(device)
    generated_images = generator(noise).detach().cpu()

    # Plot images
    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))
    for i in range(num_images):
        axes[i].imshow(generated_images[i].squeeze(), cmap="gray")
        axes[i].axis("off")
    plt.show()

generate_images(generator, latent_dim)

"""Changing num of epocs from 50 to 100 & replacing fully connected layers with convolutional layers for better image generation


---
By changing simple GAN to deep convolutonal GAN & replacing FC layers with Convolutional layers the noise of images was reduced alot & the results showed better images then before
Tuning hyperparameters for Adam optimizer also improved stability of Convolutional GANs

"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Load and Prepare MNIST Dataset
# MNIST: data preprocessing
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)) # Normalize to range [-1, 1]
])

# Load dataset
batch_size = 64
train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Define the Generator (DCGAN Style)
# Replaced Linear layers with ConvTranspose2d layers
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        # Initial projection from latent_dim to a feature map size (e.g., 128 channels of 7x7)
        self.init_size = 7
        self.channels = 128
        self.l1 = nn.Sequential(nn.Linear(latent_dim, self.channels * self.init_size ** 2))

        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2), # Upsample to 14x14
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Upsample(scale_factor=2), # Upsample to 28x28
            nn.Conv2d(64, 32, 3, stride=1, padding=1),
            nn.BatchNorm2d(32, 0.8),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(32, 1, 3, stride=1, padding=1), # Output 1 channel
            nn.Tanh() # Output range [-1, 1]
        )

    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.shape[0], self.channels, self.init_size, self.init_size) # Reshape to (Batch, 128, 7, 7)
        img = self.conv_blocks(out)
        return img

latent_dim = 100
device = "cuda" if torch.cuda.is_available() else "cpu"
generator = Generator(latent_dim).to(device)

# Define the Discriminator
# Replaced Linear layers with Conv2d layers
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            # Input: (1, 28, 28)
            nn.Conv2d(1, 32, 3, stride=2, padding=1), # -> (32, 14, 14)
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(32, 64, 3, stride=2, padding=1), # -> (64, 7, 7)
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 3, stride=2, padding=1), # -> (128, 4, 4) -- Adjusted for 28x28
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
        )

        # The height and width after the conv layers depend on padding/stride.
        # 28 -> 14 -> 7 -> 4. So final size is 128 * 4 * 4
        self.adv_layer = nn.Sequential(
            nn.Linear(128 * 4 * 4, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        out = self.model(img)
        out = out.view(out.shape[0], -1) # Flatten
        validity = self.adv_layer(out)
        return validity

discriminator = Discriminator().to(device)

# Define Loss Function and Optimizers
criterion = nn.BCELoss()

# DCGAN usually works better with slightly different Adam parameters
lr = 0.0002
generator_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# Training the loop
def train_gan(generator, discriminator, train_loader, epochs, latent_dim):
    print(f"Starting training on {device}")
    for epoch in range(epochs):
        for i, (real_images, _) in enumerate(train_loader):
            batch_size = real_images.size(0)
            real_images = real_images.to(device)

            # Labels
            real_labels = torch.ones(batch_size, 1).to(device)
            fake_labels = torch.zeros(batch_size, 1).to(device)

            #  Train Discriminator
            discriminator_optimizer.zero_grad()

            # Loss for real images
            real_outputs = discriminator(real_images)
            real_loss = criterion(real_outputs, real_labels)

            # Generate fake images
            noise = torch.randn(batch_size, latent_dim).to(device)
            fake_images = generator(noise)

            # Loss for fake images
            fake_outputs = discriminator(fake_images.detach())
            fake_loss = criterion(fake_outputs, fake_labels)

            # Total Discriminator loss
            d_loss = real_loss + fake_loss
            d_loss.backward()
            discriminator_optimizer.step()

            # Train Generator
            generator_optimizer.zero_grad()

            # Generate fake images and calculate loss
            fake_outputs = discriminator(fake_images)
            g_loss = criterion(fake_outputs, real_labels) # Fool the discriminator

            g_loss.backward()
            generator_optimizer.step()

        # Print losses for the current epoch
        print(f"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} G Loss: {g_loss.item():.4f}")

        # Visualize generated images
        if (epoch + 1) % 10 == 0:
            visualize_images(generator, latent_dim)

# Visualization Function
def visualize_images(generator, latent_dim, num_images=16):
    generator.eval()
    with torch.no_grad(): # Good practice to turn off grad for inference
        noise = torch.randn(num_images, latent_dim).to(device)
        generated_images = generator(noise).detach().cpu()

    # Plot Images
    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))
    # Handle single image case
    if num_images == 1:
        axes = [axes]

    for i in range(num_images):
        axes[i].imshow(generated_images[i].squeeze(), cmap="gray")
        axes[i].axis("off")
    plt.show()
    generator.train()

# Run the Training

epochs = 100
train_gan(generator, discriminator, train_loader, epochs, latent_dim)

# Generate and Visualize New Images (Post-Training)
def generate_images(generator, latent_dim, num_images=16):
    generator.eval()
    with torch.no_grad():
        noise = torch.randn(num_images, latent_dim).to(device)
        generated_images = generator(noise).detach().cpu()

    # Plot images
    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))
    if num_images == 1:
        axes = [axes]

    for i in range(num_images):
        axes[i].imshow(generated_images[i].squeeze(), cmap="gray")
        axes[i].axis("off")
    plt.show()

#   Generate images
generate_images(generator, latent_dim)

"""Also tried GANs for creating augmented images"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# 1. Configuration & Device Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
batch_size = 128
lr = 0.0002
beta1 = 0.5
z_dim = 100  # Size of the random noise vector (latent space)
num_epochs = 5  # Keep it low for quick testing, increase for better results

# 2. Prepare Data (Placeholder: MNIST)
# Transforming images to range [-1, 1] which is best for GANs
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Download MNIST. To use your own data, use ImageFolder here instead.
dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

# 3. Define the Generator (Creates Augmented Images)
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            # Input is Z (noise), going into a convolution
            nn.ConvTranspose2d(z_dim, 256, 7, 1, 0, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),
            nn.Tanh() # Output layer uses Tanh to map to [-1, 1]
        )

    def forward(self, input):
        return self.main(input)

# 4. Define the Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(1, 128, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 1, 7, 1, 0, bias=False),
            nn.Sigmoid() # Output probability (0 = Fake, 1 = Real)
        )

    def forward(self, input):
        return self.main(input)

# Initialize Models
netG = Generator().to(device)
netD = Discriminator().to(device)

# Loss and Optimizers
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

# 5. Training Loop
print("Starting Training")
loss_G_history = []
loss_D_history = []

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):

        # Train Discriminator: Maximize log(D(x)) + log(1 - D(G(z)))
        netD.zero_grad()

        # Train with Real Data
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), 1.0, device=device) # Real label = 1
        output = netD(real_cpu).view(-1)
        errD_real = criterion(output, label)
        errD_real.backward()

        # Train with Fake (Augmented) Data
        noise = torch.randn(b_size, z_dim, 1, 1, device=device)
        fake = netG(noise)
        label.fill_(0.0) # Fake label = 0
        output = netD(fake.detach()).view(-1)
        errD_fake = criterion(output, label)
        errD_fake.backward()

        optimizerD.step()

        # Train Generator: Maximize log(D(G(z)))
        netG.zero_grad()
        label.fill_(1.0) # Generator wants Discriminator to think these are real (1)
        output = netD(fake).view(-1)
        errG = criterion(output, label)
        errG.backward()
        optimizerG.step()

    print(f'Epoch [{epoch+1}/{num_epochs}] Loss D: {errD_real.item() + errD_fake.item():.4f} Loss G: {errG.item():.4f}')

# 6. View the Results (Augmented Images)
with torch.no_grad():
    # Generate a batch of fake images
    noise = torch.randn(64, z_dim, 1, 1, device=device)
    fake_images = netG(noise).detach().cpu()

# Plotting
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Generated Augmented Images")
plt.imshow(np.transpose(torchvision.utils.make_grid(fake_images, padding=2, normalize=True), (1,2,0)))
plt.show()

"""For the final task I am using my custom made cat annotated data that I build in previous tutorial of object detection tutorials

---
Changed grayscale size from 28 to 64. At first the epochs were kept 50 for testing the results were not so good so changed epochs to 100. To prevent overfitting of small dataset updated simple normalization to robust augmentation.
The generator architecture was switched to pure transposed convolution (DCGAN) creating a deeper network of 512 filters to handle color images. The discriminatro architecture was also replaced with Fully convolutional output
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from google.colab import drive

# 1. Mount Google Drive
drive.mount('/content/drive')

# 2. Configuration & Device Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
batch_size = 64        # Reduced slightly to be safe with memory
lr = 0.0002
beta1 = 0.5
z_dim = 100            # Size of the random noise vector
num_epochs = 200       # Increased epochs because training on custom data takes time
image_size = 64        # We will resize all cat images to 64x64

# 3. Custom Data Loader
class CustomCatDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        # Only load .jpg, .png, .jpeg files
        self.image_files = [f for f in os.listdir(root_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.image_files[idx])
        image = Image.open(img_name).convert('RGB') # Convert to RGB (3 channels)

        if self.transform:
            image = self.transform(image)

        return image, 0 # Dummy label

# Define transforms (Resize is CRITICAL here to make all images same size)
transform = transforms.Compose([
    transforms.Resize((64, 64)),           # Resize first
    transforms.RandomHorizontalFlip(p=0.5),# Randomly flip left/right
    transforms.RandomRotation(10),         # Slight rotations (+/- 10 degrees)
    transforms.ColorJitter(brightness=0.1, contrast=0.1), # Slight color variation
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

data_path = '/content/drive/MyDrive/Cat/images'

try:
    dataset = CustomCatDataset(root_dir=data_path, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    print(f"Successfully loaded {len(dataset)} images from {data_path}")
except FileNotFoundError:
    print(f"Error: Could not find path {data_path}. Please check your Drive folders.")

# 4. Define the Generator
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            # Input is Z, going into a convolution
            nn.ConvTranspose2d(z_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            # Output layer: 3 channels for RGB images
            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, input):
        return self.main(input)

# 5. Define the Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            # Input is 3 channels (RGB)
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

# Initialize Models
netG = Generator().to(device)
netD = Discriminator().to(device)

# Loss and Optimizers
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

# 6. Training Loop
print("Starting Training Loop")

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):

        # Train Discriminator
        netD.zero_grad()
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), 1.0, device=device)
        output = netD(real_cpu).view(-1)
        errD_real = criterion(output, label)
        errD_real.backward()

        noise = torch.randn(b_size, z_dim, 1, 1, device=device)
        fake = netG(noise)
        label.fill_(0.0)
        output = netD(fake.detach()).view(-1)
        errD_fake = criterion(output, label)
        errD_fake.backward()
        optimizerD.step()

        # Train Generator
        netG.zero_grad()
        label.fill_(1.0)
        output = netD(fake).view(-1)
        errG = criterion(output, label)
        errG.backward()
        optimizerG.step()

    # Print status every epoch
    print(f'Epoch [{epoch+1}/{num_epochs}] Loss D: {errD_real.item() + errD_fake.item():.4f} Loss G: {errG.item():.4f}')

# 7. Visualizing Results
with torch.no_grad():
    fake = netG(torch.randn(64, z_dim, 1, 1, device=device)).detach().cpu()
    plt.figure(figsize=(8,8))
    plt.axis("off")
    plt.title("Augmented Cat Images")
    plt.imshow(np.transpose(torchvision.utils.make_grid(fake, padding=2, normalize=True), (1,2,0)))
    plt.show()